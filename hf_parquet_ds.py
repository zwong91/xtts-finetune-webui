import pandas as pd
import pyarrow.parquet as pq
from datasets import load_dataset, Dataset
import os
import json
import librosa
import soundfile as sf
from pathlib import Path
from tqdm import tqdm
import numpy as np

class HFParquetProcessor:
    def __init__(self, dataset_name=None, local_path=None):
        """
        åˆå§‹åŒ–å¤„ç†å™¨
        Args:
            dataset_name: Hugging Faceæ•°æ®é›†åç§° (å¦‚ "mozilla-foundation/common_voice_11_0")
            local_path: æœ¬åœ°parquetæ–‡ä»¶è·¯å¾„
        """
        self.dataset_name = dataset_name
        self.local_path = local_path
        self.dataset = None
        
    def load_dataset_from_hf(self, split='train', streaming=False):
        """ä»Hugging FaceåŠ è½½æ•°æ®é›†"""
        if not self.dataset_name:
            raise ValueError("è¯·æä¾›dataset_name")
        
        print(f"æ­£åœ¨åŠ è½½æ•°æ®é›†: {self.dataset_name}")
        self.dataset = load_dataset(self.dataset_name, split=split, streaming=streaming)
        print(f"æ•°æ®é›†åŠ è½½å®Œæˆï¼ŒåŒ…å« {len(self.dataset)} æ¡è®°å½•")
        return self.dataset
    
    def load_dataset_from_local(self):
        """ä»æœ¬åœ°parquetæ–‡ä»¶åŠ è½½æ•°æ®é›†"""
        if not self.local_path:
            raise ValueError("è¯·æä¾›local_path")
        
        if os.path.isfile(self.local_path):
            # å•ä¸ªparquetæ–‡ä»¶
            print(f"åŠ è½½å•ä¸ªæ–‡ä»¶: {self.local_path}")
            df = pd.read_parquet(self.local_path)
            self.dataset = Dataset.from_pandas(df)
        elif os.path.isdir(self.local_path):
            # æ–‡ä»¶å¤¹åŒ…å«å¤šä¸ªparquetæ–‡ä»¶
            parquet_files = sorted(list(Path(self.local_path).glob("*.parquet")))
            if not parquet_files:
                raise ValueError(f"åœ¨ {self.local_path} ä¸­æœªæ‰¾åˆ°parquetæ–‡ä»¶")
            
            print(f"æ‰¾åˆ° {len(parquet_files)} ä¸ªparquetæ–‡ä»¶:")
            for file in parquet_files:
                print(f"  - {file.name}")
            
            dfs = []
            total_rows = 0
            for file in tqdm(parquet_files, desc="åŠ è½½parquetæ–‡ä»¶"):
                df = pd.read_parquet(file)
                dfs.append(df)
                total_rows += len(df)
                print(f"  {file.name}: {len(df)} æ¡è®°å½•")
            
            print(f"åˆå¹¶æ•°æ®é›†...")
            combined_df = pd.concat(dfs, ignore_index=True)
            self.dataset = Dataset.from_pandas(combined_df)
            print(f"æ€»è®¡: {total_rows} æ¡è®°å½•")
        
        print(f"æœ¬åœ°æ•°æ®é›†åŠ è½½å®Œæˆï¼ŒåŒ…å« {len(self.dataset)} æ¡è®°å½•")
        return self.dataset
    
    def explore_dataset(self):
        """æ¢ç´¢æ•°æ®é›†ç»“æ„"""
        if self.dataset is None:
            raise ValueError("è¯·å…ˆåŠ è½½æ•°æ®é›†")
        
        print("=== æ•°æ®é›†ä¿¡æ¯ ===")
        print(f"è®°å½•æ•°é‡: {len(self.dataset)}")
        print(f"å­—æ®µ: {list(self.dataset.features.keys())}")
        
        print("\n=== å­—æ®µè¯¦ç»†ä¿¡æ¯ ===")
        for key, feature in self.dataset.features.items():
            print(f"{key}: {feature}")
        
        print("\n=== æ ·æœ¬æ•°æ® ===")
        sample = self.dataset[0]
        for key, value in sample.items():
            if key == 'audio':
                if isinstance(value, dict):
                    print(f"{key}: {{")
                    for k, v in value.items():
                        if k == 'array':
                            print(f"  {k}: numpyæ•°ç»„ï¼Œå½¢çŠ¶: {np.array(v).shape}")
                        else:
                            print(f"  {k}: {v}")
                    print("}")
                else:
                    print(f"{key}: {type(value)}")
            else:
                print(f"{key}: {value}")
        
        return self.dataset.features
    
    def save_metadata(self, output_dir="./dataset_output"):
        """ä¿å­˜å…ƒæ•°æ®åˆ°JSONæ–‡ä»¶"""
        if self.dataset is None:
            raise ValueError("è¯·å…ˆåŠ è½½æ•°æ®é›†")
        
        os.makedirs(output_dir, exist_ok=True)
        
        metadata = []
        print("æ­£åœ¨æå–å…ƒæ•°æ®...")
        
        for i, sample in enumerate(tqdm(self.dataset)):
            record = {
                'id': i,
                'duration': sample.get('duration'),
                'text': sample.get('text'),
                'normalized_text': sample.get('normalized_text'),
            }
            
            # å¦‚æœæœ‰éŸ³é¢‘ä¿¡æ¯ï¼Œæ·»åŠ éŸ³é¢‘å…ƒæ•°æ®
            if 'audio' in sample and sample['audio'] is not None:
                audio_info = sample['audio']
                if isinstance(audio_info, dict):
                    record['audio_sample_rate'] = audio_info.get('sampling_rate')
                    if 'array' in audio_info:
                        record['audio_length'] = len(audio_info['array'])
            
            metadata.append(record)
        
        # ä¿å­˜å…ƒæ•°æ®
        metadata_file = os.path.join(output_dir, "metadata.json")
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        print(f"å…ƒæ•°æ®å·²ä¿å­˜åˆ°: {metadata_file}")
        return metadata
    
    def debug_audio_structure(self, num_samples=5):
        """è°ƒè¯•éŸ³é¢‘æ•°æ®ç»“æ„"""
        if self.dataset is None:
            raise ValueError("è¯·å…ˆåŠ è½½æ•°æ®é›†")
        
        print("=== éŸ³é¢‘æ•°æ®ç»“æ„è°ƒè¯• ===")
        print(f"æ•°æ®é›†æ€»æ•°: {len(self.dataset)}")
        print(f"æ£€æŸ¥å‰ {num_samples} ä¸ªæ ·æœ¬...")
        
        for i in range(min(num_samples, len(self.dataset))):
            sample = self.dataset[i]
            print(f"\n--- æ ·æœ¬ {i} ---")
            print(f"æ‰€æœ‰å­—æ®µ: {list(sample.keys())}")
            
            # æ£€æŸ¥æ¯ä¸ªå­—æ®µ
            for key, value in sample.items():
                if key == 'audio':
                    print(f"ğŸµ {key}:")
                    print(f"  ç±»å‹: {type(value)}")
                    print(f"  å€¼: {value}")
                    print(f"  æ˜¯å¦ä¸ºNone: {value is None}")
                    
                    if value is not None:
                        if isinstance(value, dict):
                            print(f"  å­—å…¸é”®: {list(value.keys())}")
                            for k, v in value.items():
                                if k == 'array':
                                    if v is not None:
                                        arr = np.array(v) if hasattr(np, 'array') else v
                                        print(f"    {k}: ç±»å‹={type(v)}, é•¿åº¦={len(v) if hasattr(v, '__len__') else 'N/A'}")
                                        if hasattr(arr, 'shape'):
                                            print(f"         å½¢çŠ¶={arr.shape}, æ•°æ®ç±»å‹={arr.dtype if hasattr(arr, 'dtype') else 'N/A'}")
                                        if hasattr(v, '__len__') and len(v) > 0:
                                            print(f"         å‰å‡ ä¸ªå€¼: {v[:5] if len(v) >= 5 else v}")
                                    else:
                                        print(f"    {k}: None")
                                else:
                                    print(f"    {k}: {v}")
                        elif isinstance(value, (list, tuple)):
                            print(f"  åˆ—è¡¨/å…ƒç»„é•¿åº¦: {len(value)}")
                            if len(value) > 0:
                                print(f"  å‰å‡ ä¸ªå€¼: {value[:5]}")
                        elif hasattr(value, '__len__'):
                            print(f"  æ•°ç»„é•¿åº¦: {len(value)}")
                else:
                    # å…¶ä»–å­—æ®µç®€å•æ˜¾ç¤º
                    value_str = str(value)[:100] + "..." if len(str(value)) > 100 else str(value)
                    print(f"  {key}: {value_str}")
        
        # ç»Ÿè®¡éŸ³é¢‘å­—æ®µæƒ…å†µ
        print(f"\n=== éŸ³é¢‘å­—æ®µç»Ÿè®¡ ===")
        audio_count = 0
        none_count = 0
        dict_count = 0
        array_count = 0
        
        for i, sample in enumerate(self.dataset):
            if 'audio' in sample:
                audio_count += 1
                if sample['audio'] is None:
                    none_count += 1
                elif isinstance(sample['audio'], dict):
                    dict_count += 1
                elif isinstance(sample['audio'], (list, tuple, np.ndarray)):
                    array_count += 1
        
        print(f"æ ·æœ¬ä¸­:")
        print(f"  æœ‰audioå­—æ®µ: {audio_count}")
        print(f"  audioä¸ºNone: {none_count}")
        print(f"  audioä¸ºå­—å…¸: {dict_count}")
        print(f"  audioä¸ºæ•°ç»„: {array_count}")

    def save_audio_files(self, output_dir="./dataset_output", audio_format="wav", max_files=None):
        """ä¿å­˜éŸ³é¢‘æ–‡ä»¶"""
        if self.dataset is None:
            raise ValueError("è¯·å…ˆåŠ è½½æ•°æ®é›†")
        
        audio_dir = os.path.join(output_dir, "audio")
        os.makedirs(audio_dir, exist_ok=True)
        
        count = 0
        max_count = max_files if max_files else len(self.dataset)
        
        print(f"æ­£åœ¨ä¿å­˜éŸ³é¢‘æ–‡ä»¶ (æ ¼å¼: {audio_format})...")
        print(f"éŸ³é¢‘ä¿å­˜è·¯å¾„: {audio_dir}")
        
        # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
        for i, sample in enumerate(tqdm(self.dataset, desc="ä¿å­˜éŸ³é¢‘")):
            if count >= max_count:
                break
                
            if 'audio' in sample and sample['audio'] is not None:
                audio_info = sample['audio']
                
                try:
                    # å¤„ç†ä¸åŒçš„éŸ³é¢‘æ•°æ®æ ¼å¼
                    audio_saved = False
                    
                    if isinstance(audio_info, dict):
                        # æƒ…å†µ1: bytesæ ¼å¼ - å®Œæ•´çš„WAVæ–‡ä»¶æ•°æ®
                        if 'bytes' in audio_info and audio_info['bytes'] is not None:
                            audio_bytes = audio_info['bytes']
                            
                            # ç”Ÿæˆæ–‡ä»¶å
                            filename = f"audio_{i:06d}.wav"  # bytesé€šå¸¸æ˜¯WAVæ ¼å¼
                            filepath = os.path.join(audio_dir, filename)
                            
                            # ç›´æ¥ä¿å­˜äºŒè¿›åˆ¶æ•°æ®
                            with open(filepath, 'wb') as f:
                                f.write(audio_bytes)
                            
                            audio_saved = True
                            count += 1
                            
                            if count == 1:  # ç¬¬ä¸€ä¸ªæ–‡ä»¶ä¿å­˜æˆåŠŸæ—¶æ˜¾ç¤ºä¿¡æ¯
                                print(f"âœ… æˆåŠŸä¿å­˜ç¬¬ä¸€ä¸ªæ–‡ä»¶: {filename}")
                                print(f"  æ–‡ä»¶å¤§å°: {len(audio_bytes)} bytes")
                                print(f"  æ–‡ä»¶æ ¼å¼: WAV (ä»bytesæ•°æ®)")
                                
                                # å°è¯•è¯»å–éŸ³é¢‘ä¿¡æ¯
                                try:
                                    import wave
                                    with wave.open(filepath, 'rb') as wav_file:
                                        frames = wav_file.getnframes()
                                        sample_rate = wav_file.getframerate()
                                        duration = frames / sample_rate
                                        print(f"  é‡‡æ ·ç‡: {sample_rate} Hz")
                                        print(f"  æ—¶é•¿: {duration:.2f} ç§’")
                                except:
                                    print("  æ— æ³•è¯»å–WAVæ–‡ä»¶è¯¦ç»†ä¿¡æ¯")
                        
                        # æƒ…å†µ2: æ•°ç»„æ ¼å¼ {'array': [...], 'sampling_rate': 16000}
                        elif 'array' in audio_info and audio_info['array'] is not None:
                            audio_array = np.array(audio_info['array'], dtype=np.float32)
                            sample_rate = audio_info.get('sampling_rate', 16000)
                            
                            # ç”Ÿæˆæ–‡ä»¶å
                            filename = f"audio_{i:06d}.{audio_format}"
                            filepath = os.path.join(audio_dir, filename)
                            
                            # ç¡®ä¿éŸ³é¢‘æ•°æ®æ˜¯æ­£ç¡®çš„æ ¼å¼
                            if audio_array.ndim > 1:
                                audio_array = audio_array.flatten()
                            
                            # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
                            sf.write(filepath, audio_array, sample_rate)
                            audio_saved = True
                            count += 1
                            
                            if count == 1:
                                print(f"âœ… æˆåŠŸä¿å­˜ç¬¬ä¸€ä¸ªæ–‡ä»¶: {filename}")
                                print(f"  æ•°ç»„å½¢çŠ¶: {audio_array.shape}")
                                print(f"  é‡‡æ ·ç‡: {sample_rate}")
                                print(f"  æ—¶é•¿: {len(audio_array)/sample_rate:.2f}ç§’")
                        
                        # æƒ…å†µ3: è·¯å¾„æ ¼å¼ {'path': '...', 'sampling_rate': 16000}
                        elif 'path' in audio_info:
                            if count < 5:  # åªæ˜¾ç¤ºå‰5ä¸ªè·¯å¾„ä¿¡æ¯
                                print(f"âš ï¸  æ ·æœ¬ {i}: éŸ³é¢‘ä¸ºè·¯å¾„å¼•ç”¨ {audio_info['path']}")
                            continue
                            
                    elif isinstance(audio_info, (list, np.ndarray)):
                        # æƒ…å†µ4: ç›´æ¥æ˜¯æ•°ç»„
                        audio_array = np.array(audio_info, dtype=np.float32)
                        sample_rate = 16000  # é»˜è®¤é‡‡æ ·ç‡
                        
                        filename = f"audio_{i:06d}.{audio_format}"
                        filepath = os.path.join(audio_dir, filename)
                        
                        if audio_array.ndim > 1:
                            audio_array = audio_array.flatten()
                        
                        sf.write(filepath, audio_array, sample_rate)
                        audio_saved = True
                        count += 1
                    
                    if not audio_saved and i < 5:  # åªæ˜¾ç¤ºå‰5ä¸ªçš„è¯¦ç»†ä¿¡æ¯
                        print(f"âŒ è·³è¿‡æ ·æœ¬ {i}: æ— æ³•å¤„ç†çš„éŸ³é¢‘æ ¼å¼")
                        
                except Exception as e:
                    if i < 5:  # åªæ˜¾ç¤ºå‰5ä¸ªçš„é”™è¯¯ä¿¡æ¯
                        print(f"âŒ ä¿å­˜æ ·æœ¬ {i} æ—¶å‡ºé”™: {e}")
                    continue
        
        print(f"å·²ä¿å­˜ {count} ä¸ªéŸ³é¢‘æ–‡ä»¶åˆ°: {audio_dir}")
        if count == 0:
            print("âš ï¸  è­¦å‘Š: æ²¡æœ‰æˆåŠŸä¿å­˜ä»»ä½•éŸ³é¢‘æ–‡ä»¶")
        else:
            print(f"ğŸ‰ æˆåŠŸä¿å­˜äº† {count} ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼")
        
        return count
    
    def save_text_files(self, output_dir="./dataset_output"):
        """ä¿å­˜æ–‡æœ¬æ–‡ä»¶"""
        if self.dataset is None:
            raise ValueError("è¯·å…ˆåŠ è½½æ•°æ®é›†")
        
        text_dir = os.path.join(output_dir, "texts")
        os.makedirs(text_dir, exist_ok=True)
        
        # ä¿å­˜åŸå§‹æ–‡æœ¬
        texts = []
        normalized_texts = []
        
        for sample in self.dataset:
            texts.append(sample.get('text', ''))
            normalized_texts.append(sample.get('normalized_text', ''))
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(os.path.join(text_dir, "texts.txt"), 'w', encoding='utf-8') as f:
            for text in texts:
                f.write(text + '\n')
        
        with open(os.path.join(text_dir, "normalized_texts.txt"), 'w', encoding='utf-8') as f:
            for text in normalized_texts:
                f.write(text + '\n')
        
        print(f"æ–‡æœ¬æ–‡ä»¶å·²ä¿å­˜åˆ°: {text_dir}")
        return len(texts)
    
    def export_to_csv(self, output_dir="./dataset_output"):
        """å¯¼å‡ºä¸ºCSVæ ¼å¼"""
        if self.dataset is None:
            raise ValueError("è¯·å…ˆåŠ è½½æ•°æ®é›†")
        
        os.makedirs(output_dir, exist_ok=True)
        
        # å‡†å¤‡æ•°æ®
        data = []
        for i, sample in enumerate(self.dataset):
            record = {
                'id': i,
                'duration': sample.get('duration'),
                'text': sample.get('text'),
                'normalized_text': sample.get('normalized_text'),
            }
            
            # æ·»åŠ éŸ³é¢‘ä¿¡æ¯
            if 'audio' in sample and sample['audio'] is not None:
                audio_info = sample['audio']
                if isinstance(audio_info, dict):
                    record['audio_sample_rate'] = audio_info.get('sampling_rate')
                    record['audio_filename'] = f"audio_{i:06d}.wav"
            
            data.append(record)
        
        # ä¿å­˜CSV
        df = pd.DataFrame(data)
        csv_file = os.path.join(output_dir, "dataset.csv")
        df.to_csv(csv_file, index=False, encoding='utf-8')
        
        print(f"CSVæ–‡ä»¶å·²ä¿å­˜åˆ°: {csv_file}")
        return df

# ä½¿ç”¨ç¤ºä¾‹
def main():
    # å¤„ç†æœ¬åœ°å¤šä¸ªparquetæ–‡ä»¶
    processor = HFParquetProcessor(local_path="zh-taiwan/train")
    processor.load_dataset_from_local()
    
    # æ¢ç´¢æ•°æ®é›†
    print("=" * 50)
    processor.explore_dataset()
    
    # ä¿å­˜æ•°æ®
    output_dir = "./zh_taiwan_dataset_output"
    
    print("=" * 50)
    print("å¼€å§‹ä¿å­˜æ•°æ®...")
    
    # ä¿å­˜å…ƒæ•°æ®
    metadata = processor.save_metadata(output_dir)
    print(f"å…ƒæ•°æ®åŒ…å« {len(metadata)} æ¡è®°å½•")
    
    # ä¿å­˜éŸ³é¢‘æ–‡ä»¶ (å¦‚æœæ•°æ®é‡å¤§ï¼Œå¯ä»¥é™åˆ¶æ•°é‡)
    audio_count = processor.save_audio_files(output_dir, max_files=len(metadata))
    print(f"ä¿å­˜äº† {audio_count} ä¸ªéŸ³é¢‘æ–‡ä»¶")
    
    # ä¿å­˜æ–‡æœ¬æ–‡ä»¶
    text_count = processor.save_text_files(output_dir)
    print(f"ä¿å­˜äº† {text_count} æ¡æ–‡æœ¬è®°å½•")
    
    # å¯¼å‡ºCSV
    df = processor.export_to_csv(output_dir)
    print(f"CSVåŒ…å« {len(df)} è¡Œæ•°æ®")
    
    print("=" * 50)
    print("æ•°æ®å¤„ç†å®Œæˆï¼")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")

# å¿«é€ŸæŸ¥çœ‹æ•°æ®é›†ä¿¡æ¯çš„å‡½æ•°
def quick_inspect(parquet_dir):
    """å¿«é€ŸæŸ¥çœ‹parquetæ–‡ä»¶ä¿¡æ¯"""
    print(f"æ£€æŸ¥ç›®å½•: {parquet_dir}")
    
    if not os.path.exists(parquet_dir):
        print(f"é”™è¯¯: ç›®å½• {parquet_dir} ä¸å­˜åœ¨")
        return
    
    parquet_files = sorted(list(Path(parquet_dir).glob("*.parquet")))
    if not parquet_files:
        print(f"åœ¨ {parquet_dir} ä¸­æœªæ‰¾åˆ°parquetæ–‡ä»¶")
        return
    
    print(f"æ‰¾åˆ° {len(parquet_files)} ä¸ªparquetæ–‡ä»¶:")
    
    total_rows = 0
    for file in parquet_files:
        # è¯»å–parquetæ–‡ä»¶ä¿¡æ¯
        table = pq.read_table(file)
        rows = len(table)
        total_rows += rows
        
        print(f"  ğŸ“ {file.name}")
        print(f"     è®°å½•æ•°: {rows:,}")
        print(f"     åˆ—æ•°: {len(table.column_names)}")
        print(f"     åˆ—å: {table.column_names}")
        print(f"     æ–‡ä»¶å¤§å°: {file.stat().st_size / 1024 / 1024:.2f} MB")
        print()
    
    print(f"æ€»è®°å½•æ•°: {total_rows:,}")
    
    # æ˜¾ç¤ºç¬¬ä¸€æ¡è®°å½•ç¤ºä¾‹
    if parquet_files:
        print("=" * 30)
        print("ç¬¬ä¸€æ¡è®°å½•ç¤ºä¾‹:")
        first_table = pq.read_table(parquet_files[0])
        first_row = first_table.slice(0, 1).to_pandas().iloc[0]
        
        for col, value in first_row.items():
            if col == 'audio':
                print(f"  {col}: <éŸ³é¢‘æ•°æ®>")
            else:
                value_str = str(value)[:100] + "..." if len(str(value)) > 100 else str(value)
                print(f"  {col}: {value_str}")

if __name__ == "__main__":
    # å…ˆå¿«é€ŸæŸ¥çœ‹æ•°æ®é›†ä¿¡æ¯  
    quick_inspect("zh-taiwan/train")
    
    print("\n" + "=" * 80 + "\n")
    
    # å†è¿›è¡Œå®Œæ•´å¤„ç†
    main()