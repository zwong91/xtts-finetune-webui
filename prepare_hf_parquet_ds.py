import pandas as pd
import pyarrow.parquet as pq
from datasets import load_dataset, Dataset
import os
import json
import librosa
import soundfile as sf
from pathlib import Path
from tqdm import tqdm
import numpy as np
from sklearn.model_selection import train_test_split

class HFParquetProcessor:
    def __init__(self, dataset_name=None, local_path=None):
        """
        åˆå§‹åŒ–å¤„ç†å™¨
        Args:
            dataset_name: Hugging Faceæ•°æ®é›†åç§° (å¦‚ "mozilla-foundation/common_voice_11_0")
            local_path: æœ¬åœ°parquetæ–‡ä»¶è·¯å¾„
        """
        self.dataset_name = dataset_name
        self.local_path = local_path
        self.dataset = None
        
    def load_dataset_from_hf(self, split='train', streaming=False):
        """ä»Hugging FaceåŠ è½½æ•°æ®é›†"""
        if not self.dataset_name:
            raise ValueError("è¯·æä¾›dataset_name")
        
        print(f"æ­£åœ¨åŠ è½½æ•°æ®é›†: {self.dataset_name}")
        self.dataset = load_dataset(self.dataset_name, split=split, streaming=streaming)
        print(f"æ•°æ®é›†åŠ è½½å®Œæˆï¼ŒåŒ…å« {len(self.dataset)} æ¡è®°å½•")
        return self.dataset
    
    def load_dataset_from_local(self):
        """ä»æœ¬åœ°parquetæ–‡ä»¶åŠ è½½æ•°æ®é›†"""
        if not self.local_path:
            raise ValueError("è¯·æä¾›local_path")
        
        if os.path.isfile(self.local_path):
            # å•ä¸ªparquetæ–‡ä»¶
            print(f"åŠ è½½å•ä¸ªæ–‡ä»¶: {self.local_path}")
            df = pd.read_parquet(self.local_path)
            self.dataset = Dataset.from_pandas(df)
        elif os.path.isdir(self.local_path):
            # æ–‡ä»¶å¤¹åŒ…å«å¤šä¸ªparquetæ–‡ä»¶
            parquet_files = sorted(list(Path(self.local_path).glob("*.parquet")))
            if not parquet_files:
                raise ValueError(f"åœ¨ {self.local_path} ä¸­æœªæ‰¾åˆ°parquetæ–‡ä»¶")
            
            print(f"æ‰¾åˆ° {len(parquet_files)} ä¸ªparquetæ–‡ä»¶:")
            for file in parquet_files:
                print(f"  - {file.name}")
            
            dfs = []
            total_rows = 0
            for file in tqdm(parquet_files, desc="åŠ è½½parquetæ–‡ä»¶"):
                df = pd.read_parquet(file)
                dfs.append(df)
                total_rows += len(df)
                print(f"  {file.name}: {len(df)} æ¡è®°å½•")
            
            print(f"åˆå¹¶æ•°æ®é›†...")
            combined_df = pd.concat(dfs, ignore_index=True)
            self.dataset = Dataset.from_pandas(combined_df)
            print(f"æ€»è®¡: {total_rows} æ¡è®°å½•")
        
        print(f"æœ¬åœ°æ•°æ®é›†åŠ è½½å®Œæˆï¼ŒåŒ…å« {len(self.dataset)} æ¡è®°å½•")
        return self.dataset
    
    def explore_dataset(self):
        """æ¢ç´¢æ•°æ®é›†ç»“æ„"""
        if self.dataset is None:
            raise ValueError("è¯·å…ˆåŠ è½½æ•°æ®é›†")
        
        print("=== æ•°æ®é›†ä¿¡æ¯ ===")
        print(f"è®°å½•æ•°é‡: {len(self.dataset)}")
        print(f"å­—æ®µ: {list(self.dataset.features.keys())}")
        
        print("\n=== å­—æ®µè¯¦ç»†ä¿¡æ¯ ===")
        for key, feature in self.dataset.features.items():
            print(f"{key}: {feature}")
        
        print("\n=== æ ·æœ¬æ•°æ® ===")
        sample = self.dataset[0]
        for key, value in sample.items():
            if key == 'audio':
                if isinstance(value, dict):
                    print(f"{key}: {{")
                    for k, v in value.items():
                        if k == 'array':
                            print(f"  {k}: numpyæ•°ç»„ï¼Œå½¢çŠ¶: {np.array(v).shape}")
                        else:
                            print(f"  {k}: {v}")
                    print("}")
                else:
                    print(f"{key}: {type(value)}")
            else:
                print(f"{key}: {value}")
        
        return self.dataset.features

    def save_organized_dataset(self, output_dir="./dataset_output", audio_format="wav", 
                             train_ratio=0.8, speaker_field=None, max_files=None):
        """
        ä¿å­˜ç»„ç»‡å¥½çš„æ•°æ®é›†
        Args:
            output_dir: è¾“å‡ºç›®å½•
            audio_format: éŸ³é¢‘æ ¼å¼ (wav, flac, mp3ç­‰)
            train_ratio: è®­ç»ƒé›†æ¯”ä¾‹ (0.8è¡¨ç¤º80%è®­ç»ƒï¼Œ20%éªŒè¯)
            speaker_field: è¯´è¯äººå­—æ®µåï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤å€¼
            max_files: æœ€å¤§å¤„ç†æ–‡ä»¶æ•°é‡
        """
        if self.dataset is None:
            raise ValueError("è¯·å…ˆåŠ è½½æ•°æ®é›†")
        
        # åˆ›å»ºä¸»è¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # æ ¹æ®éŸ³é¢‘æ ¼å¼åˆ›å»ºå­æ–‡ä»¶å¤¹
        audio_folder_name = f"{audio_format}s"  # wav -> wavs, flac -> flacs
        audio_dir = os.path.join(output_dir, audio_folder_name)
        os.makedirs(audio_dir, exist_ok=True)
        
        print(f"æ­£åœ¨ä¿å­˜æ•°æ®é›†åˆ°: {output_dir}")
        print(f"éŸ³é¢‘æ–‡ä»¶å¤¹: {audio_folder_name}")
        print(f"éŸ³é¢‘æ ¼å¼: {audio_format}")
        
        # å‡†å¤‡æ•°æ®åˆ—è¡¨
        dataset_records = []
        saved_count = 0
        max_count = max_files if max_files else len(self.dataset)
        
        print(f"å¼€å§‹å¤„ç† {min(max_count, len(self.dataset))} æ¡è®°å½•...")
        
        # å¤„ç†æ¯ä¸ªæ ·æœ¬
        for i, sample in enumerate(tqdm(self.dataset, desc="å¤„ç†æ•°æ®")):
            if saved_count >= max_count:
                break
                
            # è·å–æ–‡æœ¬
            text = sample.get('text', '').strip()
            if not text:
                continue
                
            # è·å–è¯´è¯äººä¿¡æ¯
            speaker_name = "Coqui"  # é»˜è®¤è¯´è¯äºº
            if speaker_field and speaker_field in sample:
                speaker_name = str(sample.get(speaker_field, "unknown"))
            elif 'speaker_id' in sample:
                speaker_name = str(sample.get('speaker_id', "unknown"))
            elif 'client_id' in sample:
                speaker_name = str(sample.get('client_id', "unknown"))
            elif 'speaker' in sample:
                speaker_name = str(sample.get('speaker', "unknown"))
            
            # å¤„ç†éŸ³é¢‘
            if 'audio' in sample and sample['audio'] is not None:
                audio_info = sample['audio']
                audio_saved = False
                
                try:
                    # ç”ŸæˆéŸ³é¢‘æ–‡ä»¶å
                    audio_filename = f"audio_{i:06d}_{saved_count:08d}.{audio_format}"
                    audio_filepath = os.path.join(audio_dir, audio_filename)
                    
                    if isinstance(audio_info, dict):
                        # æƒ…å†µ1: bytesæ ¼å¼
                        if 'bytes' in audio_info and audio_info['bytes'] is not None:
                            audio_bytes = audio_info['bytes']
                            
                            # å¦‚æœæ˜¯WAVæ ¼å¼çš„bytesï¼Œç›´æ¥ä¿å­˜
                            if audio_format == 'wav':
                                with open(audio_filepath, 'wb') as f:
                                    f.write(audio_bytes)
                                audio_saved = True
                            else:
                                # éœ€è¦è½¬æ¢æ ¼å¼ï¼Œå…ˆä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶å†è½¬æ¢
                                temp_path = audio_filepath + ".temp.wav"
                                with open(temp_path, 'wb') as f:
                                    f.write(audio_bytes)
                                
                                # ä½¿ç”¨librosaè¯»å–å¹¶è½¬æ¢
                                try:
                                    y, sr = librosa.load(temp_path, sr=None)
                                    sf.write(audio_filepath, y, sr)
                                    os.remove(temp_path)
                                    audio_saved = True
                                except:
                                    if os.path.exists(temp_path):
                                        os.remove(temp_path)
                        
                        # æƒ…å†µ2: æ•°ç»„æ ¼å¼
                        elif 'array' in audio_info and audio_info['array'] is not None:
                            audio_array = np.array(audio_info['array'], dtype=np.float32)
                            sample_rate = audio_info.get('sampling_rate', 16000)
                            
                            if audio_array.ndim > 1:
                                audio_array = audio_array.flatten()
                            
                            sf.write(audio_filepath, audio_array, sample_rate)
                            audio_saved = True
                    
                    elif isinstance(audio_info, (list, np.ndarray)):
                        # ç›´æ¥æ˜¯æ•°ç»„
                        audio_array = np.array(audio_info, dtype=np.float32)
                        sample_rate = 16000  # é»˜è®¤é‡‡æ ·ç‡
                        
                        if audio_array.ndim > 1:
                            audio_array = audio_array.flatten()
                        
                        sf.write(audio_filepath, audio_array, sample_rate)
                        audio_saved = True
                    
                    # å¦‚æœéŸ³é¢‘ä¿å­˜æˆåŠŸï¼Œæ·»åŠ åˆ°è®°å½•ä¸­
                    if audio_saved:
                        # æ„å»ºç›¸å¯¹è·¯å¾„
                        relative_audio_path = f"{audio_folder_name}/{audio_filename}"
                        
                        record = {
                            'audio_file': relative_audio_path,
                            'text': text,
                            'speaker_name': speaker_name
                        }
                        dataset_records.append(record)
                        saved_count += 1
                        
                        if saved_count == 1:
                            print(f"âœ… æˆåŠŸä¿å­˜ç¬¬ä¸€ä¸ªæ–‡ä»¶: {audio_filename}")
                            print(f"  æ–‡æœ¬: {text[:50]}...")
                            print(f"  è¯´è¯äºº: {speaker_name}")
                
                except Exception as e:
                    if saved_count < 5:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
                        print(f"âŒ å¤„ç†æ ·æœ¬ {i} æ—¶å‡ºé”™: {e}")
                    continue
        
        print(f"æˆåŠŸå¤„ç† {saved_count} æ¡è®°å½•")
        
        if saved_count == 0:
            print("âš ï¸  è­¦å‘Š: æ²¡æœ‰æˆåŠŸä¿å­˜ä»»ä½•æ•°æ®")
            return
        
        # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
        if train_ratio < 1.0:
            train_records, eval_records = train_test_split(
                dataset_records, 
                train_size=train_ratio, 
                random_state=42,
                shuffle=True
            )
            
            print(f"æ•°æ®é›†åˆ’åˆ†:")
            print(f"  è®­ç»ƒé›†: {len(train_records)} æ¡")
            print(f"  éªŒè¯é›†: {len(eval_records)} æ¡")
        else:
            # å…¨éƒ¨ä½œä¸ºè®­ç»ƒé›†
            train_records = dataset_records
            eval_records = []
            print(f"å…¨éƒ¨æ•°æ®ä½œä¸ºè®­ç»ƒé›†: {len(train_records)} æ¡")
        
        # ä¿å­˜metadata CSVæ–‡ä»¶
        def save_metadata_csv(records, filename):
            if not records:
                return
                
            csv_path = os.path.join(output_dir, filename)
            with open(csv_path, 'w', encoding='utf-8') as f:
                # å†™å…¥è¡¨å¤´
                f.write("audio_file|text|speaker_name\n")
                
                # å†™å…¥æ•°æ®
                for record in records:
                    # å¤„ç†æ–‡æœ¬ä¸­çš„ç‰¹æ®Šå­—ç¬¦
                    text = record['text'].replace('|', '\\|').replace('\n', ' ').replace('\r', ' ')
                    speaker = record['speaker_name'].replace('|', '\\|')
                    
                    f.write(f"{record['audio_file']}|{text}|{speaker}\n")
            
            print(f"å·²ä¿å­˜: {csv_path} ({len(records)} æ¡è®°å½•)")
        
        # ä¿å­˜è®­ç»ƒé›†metadata
        if train_records:
            save_metadata_csv(train_records, "metadata_train.csv")
        
        # ä¿å­˜éªŒè¯é›†metadata
        if eval_records:
            save_metadata_csv(eval_records, "metadata_eval.csv")
        
        # ç”Ÿæˆæ•°æ®é›†ä¿¡æ¯æ–‡ä»¶
        info = {
            "dataset_info": {
                "total_samples": saved_count,
                "train_samples": len(train_records),
                "eval_samples": len(eval_records),
                "audio_format": audio_format,
                "audio_folder": audio_folder_name,
                "train_ratio": train_ratio
            },
            "sample_record": dataset_records[0] if dataset_records else None
        }
        
        info_path = os.path.join(output_dir, "dataset_info.json")
        with open(info_path, 'w', encoding='utf-8') as f:
            json.dump(info, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ‰ æ•°æ®é›†å¤„ç†å®Œæˆï¼")
        print(f"è¾“å‡ºç›®å½•: {output_dir}")
        print(f"  â”œâ”€â”€ {audio_folder_name}/          # éŸ³é¢‘æ–‡ä»¶ç›®å½•")
        print(f"  â”œâ”€â”€ metadata_train.csv    # è®­ç»ƒé›†å…ƒæ•°æ®")
        if eval_records:
            print(f"  â”œâ”€â”€ metadata_eval.csv     # éªŒè¯é›†å…ƒæ•°æ®")
        print(f"  â””â”€â”€ dataset_info.json     # æ•°æ®é›†ä¿¡æ¯")
        
        return {
            'total_samples': saved_count,
            'train_samples': len(train_records),
            'eval_samples': len(eval_records),
            'output_dir': output_dir
        }

    def debug_audio_structure(self, num_samples=5):
        """è°ƒè¯•éŸ³é¢‘æ•°æ®ç»“æ„"""
        if self.dataset is None:
            raise ValueError("è¯·å…ˆåŠ è½½æ•°æ®é›†")
        
        print("=== éŸ³é¢‘æ•°æ®ç»“æ„è°ƒè¯• ===")
        print(f"æ•°æ®é›†æ€»æ•°: {len(self.dataset)}")
        print(f"æ£€æŸ¥å‰ {num_samples} ä¸ªæ ·æœ¬...")
        
        for i in range(min(num_samples, len(self.dataset))):
            sample = self.dataset[i]
            print(f"\n--- æ ·æœ¬ {i} ---")
            print(f"æ‰€æœ‰å­—æ®µ: {list(sample.keys())}")
            
            # æ£€æŸ¥æ¯ä¸ªå­—æ®µ
            for key, value in sample.items():
                if key == 'audio':
                    print(f"ğŸµ {key}:")
                    print(f"  ç±»å‹: {type(value)}")
                    print(f"  å€¼: {value}")
                    print(f"  æ˜¯å¦ä¸ºNone: {value is None}")
                    
                    if value is not None:
                        if isinstance(value, dict):
                            print(f"  å­—å…¸é”®: {list(value.keys())}")
                            for k, v in value.items():
                                if k == 'array':
                                    if v is not None:
                                        arr = np.array(v) if hasattr(np, 'array') else v
                                        print(f"    {k}: ç±»å‹={type(v)}, é•¿åº¦={len(v) if hasattr(v, '__len__') else 'N/A'}")
                                        if hasattr(arr, 'shape'):
                                            print(f"         å½¢çŠ¶={arr.shape}, æ•°æ®ç±»å‹={arr.dtype if hasattr(arr, 'dtype') else 'N/A'}")
                                        if hasattr(v, '__len__') and len(v) > 0:
                                            print(f"         å‰å‡ ä¸ªå€¼: {v[:5] if len(v) >= 5 else v}")
                                    else:
                                        print(f"    {k}: None")
                                else:
                                    print(f"    {k}: {v}")
                        elif isinstance(value, (list, tuple)):
                            print(f"  åˆ—è¡¨/å…ƒç»„é•¿åº¦: {len(value)}")
                            if len(value) > 0:
                                print(f"  å‰å‡ ä¸ªå€¼: {value[:5]}")
                        elif hasattr(value, '__len__'):
                            print(f"  æ•°ç»„é•¿åº¦: {len(value)}")
                else:
                    # å…¶ä»–å­—æ®µç®€å•æ˜¾ç¤º
                    value_str = str(value)[:100] + "..." if len(str(value)) > 100 else str(value)
                    print(f"  {key}: {value_str}")

# ä½¿ç”¨ç¤ºä¾‹
def main():
    # å¤„ç†æœ¬åœ°å¤šä¸ªparquetæ–‡ä»¶
    processor = HFParquetProcessor(local_path="zh-taiwan/train")
    processor.load_dataset_from_local()
    
    # æ¢ç´¢æ•°æ®é›†ç»“æ„
    print("=" * 50)
    processor.explore_dataset()
    
    # æ£€æŸ¥å‰å‡ ä¸ªæ ·æœ¬çš„ç»“æ„
    print("=" * 50)
    processor.debug_audio_structure(num_samples=3)
    
    # ä¿å­˜ç»„ç»‡å¥½çš„æ•°æ®é›†
    print("=" * 50)
    print("å¼€å§‹ä¿å­˜ç»„ç»‡åçš„æ•°æ®é›†...")
    
    result = processor.save_organized_dataset(
        output_dir="finetune_models/dataset",
        audio_format="wav",  # å¯ä»¥æ”¹ä¸º flac, mp3 ç­‰
        train_ratio=0.8,     # 80% è®­ç»ƒï¼Œ20% éªŒè¯
        speaker_field="vvvv",  # å¦‚æœæœ‰ç‰¹å®šçš„è¯´è¯äººå­—æ®µåï¼Œåœ¨è¿™é‡ŒæŒ‡å®š
        max_files=None       # é™åˆ¶å¤„ç†æ•°é‡ï¼ŒNoneè¡¨ç¤ºå¤„ç†å…¨éƒ¨
    )
    
    if result:
        print(f"\nå¤„ç†ç»“æœ:")
        print(f"  æ€»æ ·æœ¬æ•°: {result['total_samples']}")
        print(f"  è®­ç»ƒæ ·æœ¬: {result['train_samples']}")
        print(f"  éªŒè¯æ ·æœ¬: {result['eval_samples']}")
        print(f"  è¾“å‡ºç›®å½•: {result['output_dir']}")

# å¿«é€ŸæŸ¥çœ‹æ•°æ®é›†ä¿¡æ¯çš„å‡½æ•°
def quick_inspect(parquet_dir):
    """å¿«é€ŸæŸ¥çœ‹parquetæ–‡ä»¶ä¿¡æ¯"""
    print(f"æ£€æŸ¥ç›®å½•: {parquet_dir}")
    
    if not os.path.exists(parquet_dir):
        print(f"é”™è¯¯: ç›®å½• {parquet_dir} ä¸å­˜åœ¨")
        return
    
    parquet_files = sorted(list(Path(parquet_dir).glob("*.parquet")))
    if not parquet_files:
        print(f"åœ¨ {parquet_dir} ä¸­æœªæ‰¾åˆ°parquetæ–‡ä»¶")
        return
    
    print(f"æ‰¾åˆ° {len(parquet_files)} ä¸ªparquetæ–‡ä»¶:")
    
    total_rows = 0
    for file in parquet_files:
        # è¯»å–parquetæ–‡ä»¶ä¿¡æ¯
        table = pq.read_table(file)
        rows = len(table)
        total_rows += rows
        
        print(f"  ğŸ“ {file.name}")
        print(f"     è®°å½•æ•°: {rows:,}")
        print(f"     åˆ—æ•°: {len(table.column_names)}")
        print(f"     åˆ—å: {table.column_names}")
        print(f"     æ–‡ä»¶å¤§å°: {file.stat().st_size / 1024 / 1024:.2f} MB")
        print()
    
    print(f"æ€»è®°å½•æ•°: {total_rows:,}")
    
    # æ˜¾ç¤ºç¬¬ä¸€æ¡è®°å½•ç¤ºä¾‹
    if parquet_files:
        print("=" * 30)
        print("ç¬¬ä¸€æ¡è®°å½•ç¤ºä¾‹:")
        first_table = pq.read_table(parquet_files[0])
        first_row = first_table.slice(0, 1).to_pandas().iloc[0]
        
        for col, value in first_row.items():
            if col == 'audio':
                print(f"  {col}: <éŸ³é¢‘æ•°æ®>")
            else:
                value_str = str(value)[:100] + "..." if len(str(value)) > 100 else str(value)
                print(f"  {col}: {value_str}")


# uv pip install datasets pandas pyarrow librosa soundfile tqdm
if __name__ == "__main__":
    # å…ˆå¿«é€ŸæŸ¥çœ‹æ•°æ®é›†ä¿¡æ¯  
    quick_inspect("zh-taiwan/train")
    
    print("\n" + "=" * 80 + "\n")
    
    # å†è¿›è¡Œå®Œæ•´å¤„ç†
    main()